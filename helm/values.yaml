# NIM Deployment Configuration
# Meta Llama 3.1 8B Instruct on OKE

replicaCount: 1

image:
  registry: nvcr.io
  repository: nim/meta/llama-3.1-8b-instruct
  tag: "latest"
  pullPolicy: IfNotPresent

imagePullSecrets:
  - name: ngc-secret

ngc:
  apiKey: "<YOUR_NGC_API_KEY>"
  registry: nvcr.io
  username: "$oauthtoken"

model:
  name: "meta/llama-3.1-8b-instruct"
  cache:
    enabled: true
    storageClass: "oci-bv"
    size: "200Gi"  # Recommended for model caching and avoiding resource constraints

resources:
  # NVIDIA NIM Requirements: 40GB RAM minimum, 90GB recommended
  # VM.GPU.A10.1 node provides 240GB RAM (exceeds requirements)
  # Container requests 24Gi, limits 32Gi (well within node capacity)
  limits:
    nvidia.com/gpu: 1
    memory: "32Gi"   # 32GB limit (node has 240GB available)
    cpu: "8"
  requests:
    nvidia.com/gpu: 1
    memory: "24Gi"   # 24GB request (NVIDIA minimum: 40GB node memory)
    cpu: "4"

service:
  type: LoadBalancer
  port: 8000
  targetPort: 8000
  externalTrafficPolicy: Local
  annotations:
    service.beta.kubernetes.io/oci-load-balancer-shape: "flexible"
    service.beta.kubernetes.io/oci-load-balancer-shape-flex-min: "10"
    service.beta.kubernetes.io/oci-load-balancer-shape-flex-max: "10"

env:
  - name: NIM_CACHE_PATH
    value: "/model-cache"
  - name: NIM_MODEL_PROFILE
    value: "auto"
  - name: NGC_API_KEY
    valueFrom:
      secretKeyRef:
        name: nvidia-nim-ngc-api
        key: NGC_API_KEY

persistence:
  enabled: true
  storageClass: "oci-bv"
  accessMode: ReadWriteOnce
  size: 50Gi
  mountPath: /model-cache

podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000
  # seccompProfile: RuntimeDefault - DISABLED for NIM compatibility
  # NIM requires GPU syscalls that may be blocked by RuntimeDefault
  # TODO: Test with custom seccomp profile after initial deployment

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: false  # NIM requires writable filesystem for temp files and cache

nodeSelector:
  nvidia.com/gpu.product: NVIDIA-A10

tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule

affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: nvidia.com/gpu.present
              operator: In
              values:
                - "true"

topologySpreadConstraints:
  enabled: false  # DISABLED for single-zone development/testing
  maxSkew: 1
  topologyKey: topology.kubernetes.io/zone
  whenUnsatisfiable: ScheduleAnyway  # Allow scheduling even if constraints can't be met
  # TODO: Enable for production multi-zone deployments

readinessProbe:
  httpGet:
    path: /v1/health/ready
    port: 8000
  initialDelaySeconds: 15  # Reduced from 30s for faster deployment
  periodSeconds: 5         # Reduced from 10s for quicker detection
  timeoutSeconds: 3        # Reduced from 5s
  failureThreshold: 6      # Increased to compensate for faster checks

livenessProbe:
  httpGet:
    path: /v1/health/live
    port: 8000
  initialDelaySeconds: 45  # Reduced from 60s
  periodSeconds: 20        # Reduced from 30s
  timeoutSeconds: 5        # Reduced from 10s
  failureThreshold: 3

startupProbe:
  httpGet:
    path: /v1/health/startup
    port: 8000
  initialDelaySeconds: 5   # Reduced from 10s
  periodSeconds: 5         # Reduced from 10s for faster startup detection
  timeoutSeconds: 3        # Reduced from 5s
  failureThreshold: 36     # Increased to maintain same total timeout (3min)

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 3
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8000"
  prometheus.io/path: "/metrics"

serviceAccount:
  create: true
  annotations:
    oci.oraclecloud.com/principal-type: "instance"
  name: "nim-service-account"

labels:
  app.kubernetes.io/name: nvidia-nim
  app.kubernetes.io/component: inference
  app.kubernetes.io/part-of: nim-deployment

costOptimization:
  scheduleDowntime: false

